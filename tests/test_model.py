from utils.common import trace_func



def test_yourtts_download_model():
    # Load model directly
    from transformers import AutoModel
    cache_dir = "models/tts/yourtts/base"
    model = AutoModel.from_pretrained("wannaphong/khanomtan-tts-v1.0",cache_dir=cache_dir)

def test_f5_tts_direct():
    print("test_f5_tts_direct")
    """ç›´æ¥æµ‹è¯•F5-TTSå¼•æ“"""
    from core.tts.f5_tts_engine import F5TTSEngine
    import soundfile as sf
    import numpy as np
    import torch

    # é…ç½®å‚æ•°
    gpu_config = {
        "enabled": True,
        "device": "cuda" if torch.cuda.is_available() else "cpu"
    }
    performance_config = {
        "use_jit": False,
        "use_fp16": False
    }
    audio_config = {
        "input": {
            "sample_rate": 16000,
            "channels": 1
        },
        "output": {
            "sample_rate": 16000,
            "channels": 1
        }
    }

    try:
        # åˆå§‹åŒ–å¼•æ“
        engine = F5TTSEngine()

        # é…ç½®å¼•æ“
        ok = engine.configure(
            model="thai",
            voice="female_30",
            language="th",
            gpu=gpu_config,
            performance=performance_config,
            audio=audio_config
        )

        if not ok:
            print("å¼•æ“é…ç½®å¤±è´¥")
            return

        # æµ‹è¯•æ–‡æœ¬
        test_text = "à¸–à¹‰à¸²à¹ƒà¸„à¸£à¸­à¸¢à¸²à¸à¸”à¸·à¹ˆà¸¡à¸™à¹‰à¹à¸²à¸ªà¸±à¸à¹à¸à¹‰à¸§ à¸à¹‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¹ˆà¸™à¸à¸±à¸šà¸›à¸£à¸°à¸Šà¸²à¸Šà¸™à¸‚à¸­à¸‡à¹€à¸£à¸²à¹„à¸”à¹‰à¹ƒà¸™à¸‚à¸“à¸°à¸™à¸µà¹‰"

        print("å¼€å§‹åˆæˆ...")
        # æ‰§è¡Œåˆæˆ
        audio = engine.synthesize(test_text)

        if audio is None:
            print("åˆæˆå¤±è´¥")
            return

        # ä¿å­˜éŸ³é¢‘
        output_path = r"D:\github\voice-translate-pro\output\audio\test_direct.wav"
        if audio.dtype != np.float32:
            audio = audio.astype(np.float32)
        sf.write(output_path, audio, audio_config["output"]["sample_rate"])
        print(f"åˆæˆå®Œæˆï¼Œå·²ä¿å­˜åˆ°: {output_path}")

        # æ¸…ç†èµ„æº
        # engine.cleanup()

    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

def test_f5_tts():
    print("test_f5_tts")
    import torch
    import numpy as np
    import soundfile as sf
    from omegaconf import OmegaConf
    from f5_tts.infer.utils_infer import (
        preprocess_ref_audio_text,
        load_model,
        load_vocoder,
        get_tokenizer,
        infer_process,
        target_sample_rate,
        n_fft,
        hop_length,
        win_length,
        n_mel_channels,
        infer_batch_process,
    )
    from f5_tts.model import DiT
    from f5_tts.model.utils import seed_everything





# ========== è·¯å¾„é…ç½® ==========
    model_path = r"D:\github\voice-translate-pro\models\tts\f5_tts\thai\model.pt"
    vocab_path = r"D:\github\voice-translate-pro\models\tts\f5_tts\thai\vocab.txt"
    ref_audio_path = r"D:\github\voice-translate-pro\models\tts\f5_tts\thai\voice\female_30.mp3"
    REF_TEXT_PATH = r"D:\github\voice-translate-pro\models\tts\f5_tts\thai\voice\female_30.txt"
    with open(REF_TEXT_PATH, "r", encoding="utf-8") as f:
        ref_text = f.read()
    GEN_TEXT = "à¸–à¹‰à¸²à¹ƒà¸„à¸£à¸­à¸¢à¸²à¸à¸”à¸·à¹ˆà¸¡à¸™à¹‰à¹à¸²à¸ªà¸±à¸à¹à¸à¹‰à¸§ à¸à¹‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸¥à¹ˆà¸™à¸à¸±à¸šà¸›à¸£à¸°à¸Šà¸²à¸Šà¸™à¸‚à¸­à¸‡à¹€à¸£à¸²à¹„à¸”à¹‰à¹ƒà¸™à¸‚à¸“à¸°à¸™à¸µà¹‰ à¹€à¸£à¸²à¸à¹‡à¹€à¸à¸´à¹ˆà¸‡à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¹à¸¥à¹‰à¸§à¸„à¸£à¸±à¸š à¹€à¸”à¹‡à¸à¹† à¸§à¸±à¸™à¸™à¸µà¹‰à¸œà¸¡à¹€à¸•à¸£à¸µà¸¢à¸¡à¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸”à¸¹à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸„à¸£à¸¹à¸„à¸¸à¸“à¹„à¸¡à¹ˆà¹€à¸„à¸¢à¹€à¸«à¹‡à¸™à¸¡à¸²à¸à¹ˆà¸­à¸™ 2 à¸§à¸±à¸™à¸—à¸µà¹ˆà¹à¸¥à¹‰à¸§"
    OUTPUT_PATH = r"""D:\github\voice-translate-pro\output/audio/output_8.wav"""

    device = "cuda" if torch.cuda.is_available() else "cpu"
    mel_spec_type = "vocos"
    tokenizer = "custom"

    # ========== åŠ è½½ tokenizer ==========
    vocab_char_map, vocab_size = get_tokenizer(vocab_path, tokenizer)

    # ========== æ¨¡å‹å‚æ•°é…ç½® ==========
    model_cfg = dict(
        dim=1024,
        depth=22,
        heads=16,
        ff_mult=2,
        text_dim=512,
        conv_layers=4
    )

    # ========== æ„å»ºæ¨¡å‹ï¼ˆè‡ªåŠ¨å°è£…ä¸º CFMï¼‰==========
    print("ğŸ› æ­£åœ¨æ„å»ºæ¨¡å‹...")
    model = load_model(
        model_cls=DiT,
        model_cfg=model_cfg,
        ckpt_path=model_path,
        mel_spec_type=mel_spec_type,
        vocab_file=vocab_path,
        use_ema=True,
        device=device
    )
    model.eval()

    # ========== åŠ è½½ vocoder ==========
    vocoder = load_vocoder(vocoder_name=mel_spec_type, is_local=False, device=device)

    # ========== åŠ è½½å‚è€ƒéŸ³é¢‘ ==========
    ref_audio_tensor, ref_text_proc = preprocess_ref_audio_text(ref_audio_path, ref_text)

    print(f"""ref_audio_tensor:{ref_audio_tensor},ref_text_proc:{ref_text_proc}""")

    # ========== åˆæˆè¯­éŸ³ ==========
    print("ğŸ™ å¼€å§‹åˆæˆè¯­éŸ³...")
    seed_everything(42)

    # | å‚æ•°å                  | å½“å‰å€¼  | å»ºè®®è°ƒæ•´èŒƒå›´     | ä½œç”¨                        |
    # | -------------------- | ---- | ---------- | ------------------------- |
    # | `cfg_strength`       | 2.0  | 1.5 â€“ 2.8  | æ§åˆ¶ç”ŸæˆéŸ³é¢‘ä¸å‚è€ƒé£æ ¼çš„ç›¸ä¼¼åº¦ï¼ˆè¶Šé«˜è¶Šæ¥è¿‘å‚è€ƒéŸ³ï¼‰ |
    # | `sway_sampling_coef` | -1.0 | -2.0 â€“ 0.0 | æ§åˆ¶æƒ…æ„Ÿé£æ ¼çš„â€œæ‘‡æ‘†â€å¹…åº¦ï¼Œæå‡è¯­æ°”å˜åŒ–æ„Ÿ     |
    # | `speed`              | 1.0  | 0.95 â€“ 1.2 | å¾®è°ƒè¯­é€Ÿï¼Œç¨å¿«è¯­é€Ÿåœ¨ç›´æ’­å¸¦è´§ä¸­æ›´æœ‰â€œå¸å¼•åŠ›â€    |
    # | `nfe_step`           | 32   | 40 â€“ 48    | å¢åŠ å¯ä»¥æ”¹å–„åˆæˆè´¨é‡ï¼ˆä½†å¯èƒ½å¸¦æ¥å»¶è¿Ÿï¼‰       |


    speed = 1.05
    cfg_strength = 2.8
    cross_fade_duration = 0.12
    nfe_step = 48
    sway_sampling_coef = 0.2
    target_rms = -18.0
    fix_duration = None


    audio, sample_rate, _ = infer_process(
                ref_audio=ref_audio_tensor,
                ref_text=ref_text_proc,
                gen_text=GEN_TEXT,
                model_obj=model,
                vocoder=vocoder,
                mel_spec_type=mel_spec_type,
                target_rms=target_rms,
                cross_fade_duration=cross_fade_duration,
                nfe_step=nfe_step,
                cfg_strength=cfg_strength,
                sway_sampling_coef=sway_sampling_coef,
                speed=speed,
                fix_duration=fix_duration,
                device=torch.device(device)
            )

    # ========== ä¿å­˜ç»“æœ ==========
    sf.write(OUTPUT_PATH, audio, sample_rate)
    print(f"âœ… åˆæˆå®Œæˆï¼Œä¿å­˜ä¸ºï¼š{OUTPUT_PATH}")

def test_live_f5_tts():
    import torch
    import soundfile as sf
    from omegaconf import OmegaConf

    from f5_tts.infer.utils_infer import (
        preprocess_ref_audio_text,
        load_model,
        load_vocoder,
        infer_process,
        get_tokenizer,
        n_fft, hop_length, win_length,
        n_mel_channels, target_sample_rate,
    )

    from f5_tts.model import UNetT
    from f5_tts.model.utils import seed_everything


    def live_tts(
            ref_audio_path: str,
            ref_text: str,
            gen_text: str,
            model_path: str = "model.pt",
            vocab_path: str = "vocab.txt",
            output_path: str = "live_output.wav",
            use_cuda: bool = True
    ):
        # ===== è®¾ç½®è®¾å¤‡ =====
        device = "cuda" if use_cuda and torch.cuda.is_available() else "cpu"
        device_torch = torch.device(device)

        # ===== åŠ è½½ tokenizer =====
        vocab_char_map, vocab_size = get_tokenizer(vocab_path, "custom")

        # ===== æ¨¡å‹é…ç½®ï¼ˆUNetT æ›´é€‚åˆæƒ…æ„Ÿè¯­è°ƒï¼‰ =====
        model_cfg = dict(
            dim=1024,
            depth=20,
            heads=16,
            ff_mult=2,
            text_dim=512,
            conv_layers=4
        )

        # ===== åŠ è½½æ¨¡å‹ï¼ˆå°è£…ä¸º CFMï¼‰ =====
        model = load_model(
            model_cls=UNetT,
            model_cfg=model_cfg,
            ckpt_path=model_path,
            mel_spec_type="bigvgan",
            vocab_file=vocab_path,
            use_ema=True,
            device=device
        )
        model.eval()

        # ===== åŠ è½½ vocoder =====
        vocoder = load_vocoder(vocoder_name="bigvgan", is_local=False, device=device)

        # ===== é¢„å¤„ç†å‚è€ƒè¯­éŸ³ =====
        ref_audio_tensor, ref_text_proc = preprocess_ref_audio_text(ref_audio_path, ref_text)

        # ===== è®¾ç½®éšæœºç§å­ç¡®ä¿ä¸€è‡´æ€§ =====
        seed_everything(42)

        # ===== åˆæˆè¯­éŸ³ =====
        audio, sample_rate, _ = infer_process(
            ref_audio=ref_audio_tensor,
            ref_text=ref_text_proc,
            gen_text=gen_text,
            model_obj=model,
            vocoder=vocoder,
            mel_spec_type="bigvgan",
            target_rms=-19.0,
            cross_fade_duration=0.12,
            nfe_step=48,
            cfg_strength=2.8,
            sway_sampling_coef=-1.0,
            speed=1.05,
            fix_duration=None,
            device=device_torch,
        )

        # ===== ä¿å­˜è¾“å‡ºéŸ³é¢‘ =====
        sf.write(output_path, audio, sample_rate)
        print(f"âœ… åˆæˆå®Œæˆï¼Œè¾“å‡ºè·¯å¾„: {output_path}")

    MODEL_PATH = r"/models/tts/f5_tts/thai/model.pt"
    VOCAB_PATH = r"D:\github\voice-translate-pro\models\tts\f5_tts\thai\vocab.txt"
    REF_AUDIO_PATH = r"D:\github\voice-translate-pro\tests\ref.wav"
    REF_TEXT = "à¹„à¸”à¹‰à¸£à¸±à¸šà¸‚à¹ˆà¸²à¸§à¸„à¸£à¸²à¸§à¸‚à¸­à¸‡à¹€à¸£à¸²à¸—à¸µà¹ˆà¸ˆà¸°à¸«à¸²à¸—à¸µà¹ˆà¸¡à¸±à¸™à¹€à¸›à¹‡à¸™à¹„à¸›à¸—à¸µà¹ˆà¸ˆà¸°à¸ˆà¸±à¸”à¸‚à¸¶à¹‰à¸™."  # æ›¿æ¢ä¸ºä½ çš„å‚è€ƒè¯­éŸ³çš„å†…å®¹
    GEN_TEXT = "à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¹ˆà¸° à¸¢à¸´à¸™à¸”à¸µà¸•à¹‰à¸­à¸™à¸£à¸±à¸šà¹€à¸‚à¹‰à¸²à¸ªà¸¹à¹ˆà¸£à¹‰à¸²à¸™à¸‚à¸­à¸‡à¹€à¸£à¸² à¸«à¸§à¸±à¸‡à¸§à¹ˆà¸²à¸„à¸¸à¸“à¸ˆà¸°à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸¸à¸‚à¸à¸±à¸šà¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸‹à¸·à¹‰à¸­à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸™à¸§à¸±à¸™à¸™à¸µà¹‰"
    OUTPUT_PATH = f"""live_output_{2}.wav"""

    live_tts(
        ref_audio_path=REF_AUDIO_PATH,
        ref_text=REF_TEXT,
        gen_text=GEN_TEXT,
        model_path=MODEL_PATH,
        vocab_path=VOCAB_PATH,
        output_path=OUTPUT_PATH,
        use_cuda=True,
    )

def test_diff():
    test_f5_tts_direct()
    print("===========================================================================================")
    test_f5_tts()



